{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lit_Search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN0HYtaj9GBlM+SctiELkas",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kecbenson/DATA698/blob/master/Lit_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MISomHUWt75e"
      },
      "source": [
        "# Applying Deep Learning in Keras to a High-Energy Particle Physics Dataset\n",
        "\n",
        "## *Kevin Benson*\n",
        "\n",
        "### *October 25, 2020*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_T8y7Mst7-v"
      },
      "source": [
        "## Relevant literature\n",
        "\n",
        "The application of machine learning (\"ML\") methods to statistical analysis in high energy physics (\"HEP\") has received increasing research interest over the last decade.  The topic has become an academic field in its own right, with an active research community and large body of published work.  It continues to be a rich area for further research, with development of numerous applications in HEP and new use cases in other areas of physics.  Below we provide a brief review of several articles and other relevant resources.\n",
        "\n",
        "A good starting point is the [lecture](https://cmsa.fas.harvard.edu/amir-farbin-deep-learning-in-high-energy-physics/) by Amir Farbin in 2016 [1], which gives an introduction to the field and different directions of research effort.  Farbin describes various experiments in high energy physics and the nature of the data collected, and thenn explains the challenges of data analysis and the benefits provided by deep learning.  An important point he makes is the availabilty of high quality public datasets that can be used for benchmarking and testing of new algorithms.  Another good place to start is the [HEP-ML Resources repository](https://github.com/iml-wg/HEP-ML-Resources) maintained by the Inter-Experimental LHC Machine Learning Working Group [2].  The repo contains a listing and links to a variety of useful learning materials (lectures, tutorials, etc.), software, public datasets, academic papers, and other resources.\n",
        "\n",
        "A more advanced introduction is given in a 2018 community white paper [3], written by a large cross section of researchers in the high energy physics and machine learning fields.  The white paper gives a broad overview of different machine learning applications in HEP including simulation of particle / detector interactions, event reconstruction and identification, feature extraction, and end-to-end deep learning, among others, and highlights challenges and promising areas for future research and development. The white paper also emphasizes opportunities for collaboration between the HEP and ML communities, including both academia and industry, with a particular focus on ML software and tools as well as computing and hardware resources.  The paper notes (as of its writing in 2017) that typical ML applications in HEP may \"require up to 1 GPU-week to train a single model\", and that with hyper-parameter tuning, a project may \"easily require up to a full GPU-year for training.\"\n",
        "\n",
        "Guest, Cranmer, and Whiteson [4] provide a survey of selected machine learning techniques applied to data analysis in high-energy physics.  The authors start from first principles and explain the problem of particle detection as one of identifying extremely low-frequency signals in a high-dimensional data space.  They outline the mathematical framework of deep learning, and describe how deep neural networks can provide hierarchical representations of the data using modular, differentiable components.  They describe early machine learning approaches such as \"shallow\" neural networks based on highly engineered data features in a lower-dimensional space, and discuss how the field has moved to deep neural networks based on lower-level data in a much higher-dimensional space.  Deep neural network models tend to obviate the need for extensive feature engineering and pre-processing, while at the same improving classification performance.  Of course, this comes at the cost of more intensive computational resources and data infrastructure.  The authors describe several applications of deep learning to HEP, including event reconstruction, selection, and identification, and highlight several challenges.  One such challenge relates to the \"trade-off between performance and interpretability\", as the \"non-parametric nature of the neural network approach make it very difficult to interpret the solution.\"\n",
        "\n",
        "The research piece by Baldi, Sadowski, and Whiteson [5] is one of the primary papers that motivate this project.  In this paper, the authors focus on classification of signal-versus-background events based on simulated HEP data.  They demonstrate that deep learning tools based on neural networks can effectively discriminate between signal events (new particles) and background noise.  The authors consider two benchmark datasets relating to particle detection of the Higgs boson and supersymmetry particles.  In both cases they construct classification models based on boosted decision trees, shallow neural networks, and deep neural networks.  Their results indicate that deep neural networks are more effective at classification than the other two methods, and also do not require high-level feature engineering.  Using deep neural network models, they were able to achieve AUC scores of ~0.88 for classification of both the Higgs and supersymmetry datasets.  The models were implemented using Theano and Pylearn2 libraries in Python (which as of 2020 are no longer supported), in a GPU (NVIDIA) computing platform. Both the [Higgs](archive.ics.uci.edu/ml/datasets/HIGGS) and [supersymmetry](archive.ics.uci.edu/ml/datasets/SUSY) datasets were made publicly available at the UCI Machine Learning Repository.\n",
        "\n",
        "Ojika, Acosta, Ross, et. al. [6] also investigated deep learning methods\n",
        "applied to data analysis of the benchmark Higgs dataset (the same dataset published in reference [5]).  The authors developed two neural network models based on two and three sequential layers, and then evaluated their classification performance on the Higgs dataset, achieving AUC scores in the 0.7 - 0.8 range.  The models were implemented in TensorFlow and Theano, running on a supercomputer cluster at the San Diego Supercomputing Center.  The results of the analysis indicated that the second model with three sequential layers generated stronger prediction accuracy.  The authors suggest ideas for further work, including increasing the number of network layers, comparing different loss optimizers, and developing more efficient computational design. \n",
        "\n",
        "Strong [7] conducted an exhaustive investigation of deep learning techniques applied to a binary classification problem, using the 2014 Higgs ML Kaggle dataset.  The various models were evaluated with a variety of performance metrics as well as the time required for training and inference.  Some of the advanced techniques explored in the paper include data augmentation, learning rate and momentum scheduling, ensembling, and alternative model architectures.  Alternative architectures included tuning of various hyper-parameters including various activation functions (ReLU, PReLU, SELU), densely connected layers, number of hidden layers (depth), number of neurons per hidden layer (width), dropout rates, and amount of $L_2$ regularization.  The author found that various models were able to achieve performance metrics similar to the winning solutions of the Kaggle challenge, but required significantly shorter training time and less computational resources.  The author developed and implemented the models using the Python libraries PyTorch and Lumin (a wrapper library developed by the author), and used several CPU and GPU (NVIDIA) hardware configurations.\n",
        "\n",
        "A variety of authors have explored representing HEP observational data as images, and adapting deep learning image-processing techniques for classification.  Racah, Ko, Sadowski, et. al. [8] analyzed experimental data from the Daya Bay neutrino experiment, and applied both unsupervised and supervised convolutional neural networks to learn high-level representations of the raw data.  The unsupervised learning approach was used to obtain well-defined clusters in the data, which might be related to distinct underlying physics phenomena.  The supervised learning approach was used to develop a multi-class classifier that achieved accuracy of greater than 0.97, which exceeded the performance of support vector machine (SVM) and k-nearest neighbor (k-NN) classifiers.  The deep learning modeling was implemented in neon (an open source library) using Cray XC computing systems at the National Energy Research Scientific Computing Center.\n",
        "\n",
        "de Oliveira, Kagan, Mackey, et. al. [9] analyzed simulated HEP collision data as \"jet images\", and applied ML and computer vision techniques to the low-level data to find higher-level representations of the data.  They used convolution networks with fully connected layers for event classification, which provided greater discrimination power than more traditional approaches.  The deep learning models were also used for visualization of the raw data as well as feature selection.  The deep learning modeling was conducted in Python using the Keras library in a GPU (NVIDIA) computing environment.\n",
        "\n",
        "Andrews, Paulini, Gleyzer, et. al. [10] constructed image-based classfiers that discriminate signal versus background events for simulated detector data from the Large Hadron Collider (LHC) at CERN.  The authors developed \"end-to-end\" event classifiers, in which the classifiers are applied directly to the low-level detector data as input.  Using the 2012 CMS Simulated Open Data (a public dataset from CERN), they developed convolutional neural networks trained on composite images reconstructed from the raw data; these models exhibited robust performance, with AUC scores of 0.71 to 0.97 for a range of classification tasks.  The models were implemented using the PyTorch library on a GPU (NVIDIA) computing platform.\n",
        "\n",
        "In a different application of ML to HEP, Brehmer, Cranmer, Louppe, et. al. [11] used a variety of neural network techniques to analyze detector data and infer statistical properties (including likelihood ratios) of fundamental parameters relating to Standard Model physics.  The statistical properties can be viewed as a form of dimensionality reduction (from the raw high-dimensional observables to the low-dimensional statistical scores), which scales efficiently with larger-size datasets.  Importantly, the statistical properties and likelihood ratios can be used to place tighter constraints (upper or lower bounds) on fundamental physics parameters than available using more traditional approaches.\n",
        "\n",
        "Finally, Crispim Romao, Castro, Milhano, et. al. [12] described a new metric for particle collisions (the \"energy mover's distance\"), which can be used as a high-level feature to improve discrimination power in multi-class event classifiers.  The authors trained dense neural networks to perform event classification of simulated data from the LHC at CERN.  They found that including the new metric as an input feature contributed to greater discrimination performance (and higher AUC scores) compared to not including it.  The models were implemented using the Keras and TensorFlow 2.0 libraries in a GPU (NVIDIA) computing environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hW4WMoEt8Jf"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] Farbin, A. \"Deep Learning in High Energy Physics.\"  Harvard University Center of Mathematical Sciences and Applications, https://cmsa.fas.harvard.edu/amir-farbin-deep-learning-in-high-energy-physics/, 2016.\n",
        "\n",
        "[2] Inter-Experimental LHC Machine Learning Working Group.  HEP-ML Resources GitHub repository, https://github.com/iml-wg/HEP-ML-Resources.\n",
        "\n",
        "[3] Albertsson, K., P. Altoe, D. Anderson, et. al.  \"Machine Learning in High Energy Physics Community White Paper.\"  Journal of Physics: Conf. Series 1085 (2018).\n",
        "\n",
        "[4] Guest, D., K Cranmer, and D Whiteson.  \"Deep Learning and Its Application to LHC Physics.\"  Annual Review of Nuclear and Particle Science 2018 (68:1-22).\n",
        "\n",
        "[5] Baldi, P., P. Sadowski, and D. Whiteson.  “Searching for exotic particles in high-energy physics with deep learning.”  Nature Communications 5 (July 2, 2014).  \n",
        "\n",
        "[6] Ojika, D., D. Acosta, A. Gordon-Ross, et. al.  \"Accelerating High-energy Physics Exploration with Deep Learning.\"  PEARC17: Proceedings of the Practice and Experience in Advanced Research Computing 2017, Article Number 37.\n",
        "\n",
        "[7] Strong, G.  \"On the impact of selected modern deep-learning techniques to the performance and celerity of classificaiton models in an experimental high-energy physics use case.\"  Machine Learning: Science and Technology 1 (2020).\n",
        "\n",
        "[8] Racah, E., S. Ko, P. Sadowski, et.al.  \"Revealing Fundamental Physics from the Daya Bay Neutrino Experiment using Deep Neural Networks.\"  arXiv preprint arXiv:1601.07621v3 [stat.ML], 6 Dec 2016. \n",
        "\n",
        "[9] de Oliveira, L., M. Kagan, L. Mackey, et.al. \"Jet-Images -- Deep Learning Edition.\"  arXiv preprint arXiv:1511.05190v3 [hep-ph], 22 Jan 2017.\n",
        "\n",
        "[10] Andrews, M., M. Paulini, S. Gleyzer, et. al.  \"End-to-End Physics Event Classification with CMS Open Data.\"  arXiv preprint arXiv:1807.11916v2 [hep-ex], 24 Jul 2019.\n",
        "\n",
        "[11] Brehmer, J., K. Cranmer, G. Louppe, et. al.  \"A guide to constraining effective field theories with machine learning.\"  Physical Review D 98, 052004 (2018).\n",
        "\n",
        "[12] Crispim Romao, M., N. Castro, J. Milhano, et. al.  \"Use of a Generalized Energy Mover's Distance in the Search for Rare Phenomena at Colliders.\"  arXiv preprint arXiv:2004.09360v1 [hep-ph], 20 Apr 2020.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "google colab\n",
        "\n",
        "google GCP\n",
        "\n",
        "keras\n",
        "\n",
        "chollet\n",
        "\n",
        "\n",
        "\n",
        "Keras (https://keras.io/) \n",
        "\n",
        "TensorFlow (https://www.tensorflow.org/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okSSzlQ4hyzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}